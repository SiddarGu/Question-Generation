{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using T5 Transformer to Generate Text\n",
    "Code Modified from [this Github repo](https://github.com/KristiyanVachev/Leaf-Question-Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple\n",
    "import tqdm.notebook as tq\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5TokenizerFast as T5Tokenizer\n",
    "    )\n",
    "\n",
    "# Constants\n",
    "MODEL_NAME = 't5-small'\n",
    "LEARNING_RATE = 0.0001\n",
    "SOURCE_MAX_TOKEN_LEN = 300\n",
    "TARGET_MAX_TOKEN_LEN = 80\n",
    "SEP_TOKEN = '<sep>'\n",
    "TOKENIZER_LEN = 32101 #after adding the new <sep> token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "from nltk import tokenize\n",
    "from scipy import stats\n",
    "from IPython.core.debugger import set_trace\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context_para</th>\n",
       "      <th>context_sent</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>answer_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>It is a replica of the grotto at Lourdes, Fran...</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>515</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>Immediately in front of the Main Building and ...</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>188</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>Next to the Main Building is the Basilica of t...</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>279</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>Immediately behind the basilica is the Grotto,...</td>\n",
       "      <td>a Marian place of prayer and reflection</td>\n",
       "      <td>381</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>Atop the Main Building's gold dome is a golden...</td>\n",
       "      <td>a golden statue of the Virgin Mary</td>\n",
       "      <td>92</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                                        context_para  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "3  Architecturally, the school has a Catholic cha...   \n",
       "4  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                        context_sent  \\\n",
       "0  It is a replica of the grotto at Lourdes, Fran...   \n",
       "1  Immediately in front of the Main Building and ...   \n",
       "2  Next to the Main Building is the Basilica of t...   \n",
       "3  Immediately behind the basilica is the Grotto,...   \n",
       "4  Atop the Main Building's gold dome is a golden...   \n",
       "\n",
       "                               answer_text  answer_start  answer_end  \n",
       "0               Saint Bernadette Soubirous           515         541  \n",
       "1                a copper statue of Christ           188         213  \n",
       "2                        the Main Building           279         296  \n",
       "3  a Marian place of prayer and reflection           381         420  \n",
       "4       a golden statue of the Virgin Mary            92         126  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_train_df = pd.read_csv('train_df.csv')\n",
    "squad_dev_df = pd.read_csv('dev_df.csv')\n",
    "squad_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75721, 3) train_df\n",
      "(10570, 3) dev_df\n",
      "(11877, 3) test_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11877</th>\n",
       "      <td>What is heresy mainly at odds with?</td>\n",
       "      <td>Heresy is any provocative belief or theory tha...</td>\n",
       "      <td>established beliefs or customs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11878</th>\n",
       "      <td>What is a person called is practicing heresy?</td>\n",
       "      <td>Heresy is any provocative belief or theory tha...</td>\n",
       "      <td>A heretic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11879</th>\n",
       "      <td>What religions and idea of thought is heresy c...</td>\n",
       "      <td>The term is usually used to refer to violation...</td>\n",
       "      <td>Christianity, Judaism, Islam and Marxism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11880</th>\n",
       "      <td>What cultures are listed as examples of discip...</td>\n",
       "      <td>In certain historical Christian, Islamic and J...</td>\n",
       "      <td>Christian, Islamic and Jewish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11881</th>\n",
       "      <td>What language does the term heresy find its ro...</td>\n",
       "      <td>The term heresy is from Greek αἵρεσις original...</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question  \\\n",
       "11877                What is heresy mainly at odds with?   \n",
       "11878      What is a person called is practicing heresy?   \n",
       "11879  What religions and idea of thought is heresy c...   \n",
       "11880  What cultures are listed as examples of discip...   \n",
       "11881  What language does the term heresy find its ro...   \n",
       "\n",
       "                                                 context  \\\n",
       "11877  Heresy is any provocative belief or theory tha...   \n",
       "11878  Heresy is any provocative belief or theory tha...   \n",
       "11879  The term is usually used to refer to violation...   \n",
       "11880  In certain historical Christian, Islamic and J...   \n",
       "11881  The term heresy is from Greek αἵρεσις original...   \n",
       "\n",
       "                                    answer_text  \n",
       "11877            established beliefs or customs  \n",
       "11878                                 A heretic  \n",
       "11879  Christianity, Judaism, Islam and Marxism  \n",
       "11880             Christian, Islamic and Jewish  \n",
       "11881                                     Greek  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_name = 'context_para'\n",
    "drop_context = 'context_sent' \n",
    "df = squad_train_df.copy()\n",
    "# print(df.shape, ' :copy')\n",
    "\n",
    "df = df.dropna() # One missing answer_text. Will fix it later.\n",
    "# print(df.shape, ' :drop na')\n",
    "\n",
    "#Dropping duplicates\n",
    "# df = df.drop_duplicates(subset=['context_sent']).reset_index(drop=True)\n",
    "# print(df.shape, ' :dropping duplicate sentence')\n",
    "\n",
    "df.rename(columns = {context_name: 'context'}, inplace=True)\n",
    "df.drop(columns=[drop_context, 'answer_start', 'answer_end'], inplace=True) #answer_start and answer_end are not needed and are for the paragraph\n",
    "# print(df.shape, ' :final')\n",
    "\n",
    "test_df = df[:11877]\n",
    "train_df = df[11877:]\n",
    "\n",
    "## Dev set\n",
    "dev_df = squad_dev_df.copy()\n",
    "dev_df.rename(columns = {context_name: 'context'}, inplace=True)\n",
    "dev_df.drop(columns=[drop_context, 'answer_start', 'answer_end'], inplace=True)\n",
    "\n",
    "print(train_df.shape, 'train_df')\n",
    "print(dev_df.shape, 'dev_df')\n",
    "print(test_df.shape, 'test_df')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP_TOKEN = '<sep>'\n",
    "MASKING_CHANCE = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        source_max_token_len: int,\n",
    "        target_max_token_len: int\n",
    "        ):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "\n",
    "        if np.random.rand() > MASKING_CHANCE:\n",
    "            answer = data_row['answer_text']\n",
    "        else:\n",
    "            answer = '[MASK]'\n",
    "\n",
    "        source_encoding = tokenizer(\n",
    "            '{} {} {}'.format(answer, SEP_TOKEN, data_row['context']),\n",
    "            max_length= self.source_max_token_len,\n",
    "            padding='max_length',\n",
    "            truncation= True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt'\n",
    "            )\n",
    "    \n",
    "        target_encoding = tokenizer(\n",
    "            '{} {} {}'.format(data_row['answer_text'], SEP_TOKEN, data_row['question']),\n",
    "            max_length=self.target_max_token_len,\n",
    "            padding='max_length',\n",
    "            truncation = True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt'\n",
    "            )\n",
    "\n",
    "        labels = target_encoding['input_ids']  \n",
    "        labels[labels == 0] = -100\n",
    "\n",
    "        return dict(\n",
    "            answer_text = data_row['answer_text'],\n",
    "            context = data_row['context'],\n",
    "            question = data_row['question'],\n",
    "            input_ids = source_encoding['input_ids'].flatten(),\n",
    "            attention_mask = source_encoding['attention_mask'].flatten(),\n",
    "            labels=labels.flatten()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df: pd.DataFrame,\n",
    "        val_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        batch_size,\n",
    "        source_max_token_len: int,\n",
    "        target_max_token_len: int\n",
    "        ): \n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = QGDataset(self.train_df, self.tokenizer, self.source_max_token_len, self.target_max_token_len)\n",
    "        self.val_dataset = QGDataset(self.val_df, self.tokenizer, self.source_max_token_len, self.target_max_token_len)\n",
    "        self.test_dataset = QGDataset(self.test_df, self.tokenizer, self.source_max_token_len, self.target_max_token_len)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size = self.batch_size, shuffle=True, num_workers = 16)\n",
    "\n",
    "    def val_dataloader(self): \n",
    "        return DataLoader(self.val_dataset, batch_size=1, num_workers=16)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=1, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 't5-small'\n",
    "SOURCE_MAX_TOKEN_LEN = 300\n",
    "TARGET_MAX_TOKEN_LEN = 80\n",
    "\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking 1.0 %\n",
      "757 of 75721\n",
      "105 of 10570\n",
      "118 of 11877\n"
     ]
    }
   ],
   "source": [
    "DF_TAKE_PERCENTAGE = 0.01\n",
    "\n",
    "TAKE_TRAIN = int(len(train_df) * DF_TAKE_PERCENTAGE)\n",
    "TAKE_DEV = int(len(dev_df) * DF_TAKE_PERCENTAGE)\n",
    "TAKE_TEST = int(len(test_df) * DF_TAKE_PERCENTAGE)\n",
    "\n",
    "print('Taking', DF_TAKE_PERCENTAGE * 100, '%')\n",
    "print(TAKE_TRAIN, 'of', len(train_df))\n",
    "print(TAKE_DEV, 'of', len(dev_df))\n",
    "print(TAKE_TEST, 'of', len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(757, 3) (105, 3) (118, 3)\n",
      "tokenizer len before:  32100\n",
      "tokenizer len after:  32101\n"
     ]
    }
   ],
   "source": [
    "print(train_df[:TAKE_TRAIN].shape, dev_df[:TAKE_DEV].shape, test_df[:TAKE_TEST].shape)\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "print('tokenizer len before: ', len(tokenizer))\n",
    "tokenizer.add_tokens(SEP_TOKEN)\n",
    "print('tokenizer len after: ', len(tokenizer))\n",
    "TOKENIZER_LEN = len(tokenizer)\n",
    "\n",
    "data_module = QGDataModule(train_df[:TAKE_TRAIN], dev_df[:TAKE_DEV], test_df[:TAKE_TEST], tokenizer, BATCH_SIZE, SOURCE_MAX_TOKEN_LEN, TARGET_MAX_TOKEN_LEN)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
    "        self.model.resize_token_embeddings(TOKENIZER_LEN) #resizing after adding new tokens to the tokenizer\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        return output.loss, output.logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        loss, output = self(input_ids, attention_mask, labels)\n",
    "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        loss, output = self(input_ids, attention_mask, labels)\n",
    "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        loss, output = self(input_ids, attention_mask, labels)\n",
    "        self.log('test_loss', loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "  \n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='checkpoints',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=-1,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=N_EPOCHS,\n",
    "    accelerator='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "241.971   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9c6c32f050444c8f9f8088686dc6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (48) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8e3d0e72fb436a8f7e820c5ac9c480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7c33023f7645e1998d68f4b71f5d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff612c18a6d4164bca141e1c9499949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7538b057644424b393f2c6cda6be6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737999f289cb4168aa0948b311cebe55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c90616b3ab4ae09732ef4bea3caf26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = QGModel()\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(qgmodel: QGModel, answer: str, context: str) -> str:\n",
    "    source_encoding = tokenizer(\n",
    "        '{} {} {}'.format(answer, SEP_TOKEN, context),\n",
    "        max_length=SOURCE_MAX_TOKEN_LEN,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    generated_ids = qgmodel.model.generate(\n",
    "        input_ids=source_encoding['input_ids'],\n",
    "        attention_mask=source_encoding['attention_mask'],\n",
    "        num_beams=1,\n",
    "        max_length=TARGET_MAX_TOKEN_LEN,\n",
    "        repetition_penalty=2.5,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=True,\n",
    "        use_cache=True\n",
    "    )\n",
    "\n",
    "    preds = {\n",
    "        tokenizer.decode(generated_id, skip_special_tokens=False, clean_up_tokenization_spaces=True)\n",
    "        for generated_id in generated_ids\n",
    "    }\n",
    "\n",
    "    return ''.join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(generated: str, answer: str, context:str, original_question: str = ''):\n",
    "    print('Generated: ', generated)\n",
    "    if original_question:\n",
    "        print('Original : ', original_question)\n",
    "\n",
    "    print()\n",
    "    print('Answer: ', answer)\n",
    "    print('Conext: ', context)\n",
    "    print('-----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:  <pad> Notre Dame<extra_id_92> What is the Notre Dame's global Adaptation Index?</s>\n",
      "Original :  The Kellogg Institute for International Studies is part of which university?\n",
      "\n",
      "Answer:  Notre Dame\n",
      "Conext:  As of 2012[update] research continued in many fields. The university president, John Jenkins, described his hope that Notre Dame would become \"one of the pre–eminent research institutions in the world\" in his inaugural address. The university has many multi-disciplinary institutes devoted to research in varying fields, including the Medieval Institute, the Kellogg Institute for International Studies, the Kroc Institute for International Peace studies, and the Center for Social Concerns. Recent research includes work on family conflict and child development, genome mapping, the increasing trade deficit of the United States with China, studies in fluid mechanics, computational science and engineering, and marketing trends on the Internet. As of 2013, the university is home to the Notre Dame Global Adaptation Index which ranks countries annually based on how vulnerable they are to climate change and how prepared they are to adapt.\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "sample_question = test_df.iloc[69]\n",
    "\n",
    "generated = generate(model, sample_question['answer_text'], sample_question['context'])\n",
    "show_result(generated, sample_question['answer_text'], sample_question['context'], sample_question['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'multitask-qg-ag.ckpt'\n",
    "\n",
    "best_model = QGModel.load_from_checkpoint(checkpoint_path)\n",
    "best_model.freeze()\n",
    "best_model.eval()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(qgmodel: QGModel, answer: str, context: str) -> str:\n",
    "    source_encoding = tokenizer(\n",
    "        '{} {} {}'.format(answer, SEP_TOKEN, context),\n",
    "        max_length=SOURCE_MAX_TOKEN_LEN,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    generated_ids = qgmodel.model.generate(\n",
    "        input_ids=source_encoding['input_ids'],\n",
    "        attention_mask=source_encoding['attention_mask'],\n",
    "        num_beams=1,\n",
    "        max_length=TARGET_MAX_TOKEN_LEN,\n",
    "        repetition_penalty=2.5,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=True,\n",
    "        use_cache=True\n",
    "    )\n",
    "\n",
    "    preds = {\n",
    "        tokenizer.decode(generated_id, skip_special_tokens=False, clean_up_tokenization_spaces=True)\n",
    "        for generated_id in generated_ids\n",
    "    }\n",
    "\n",
    "    return ''.join(preds)\n",
    "\n",
    "def show_result(generated: str, answer: str, context:str, original_question: str = ''):\n",
    "    print('Generated: ', generated)\n",
    "    if original_question:\n",
    "        print('Original : ', original_question)\n",
    "\n",
    "    print()\n",
    "    print('Answer: ', answer)\n",
    "    print('Conext: ', context)\n",
    "    print('-----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:  <pad> Washington Hall<sep> What was the name of the music hall that hosted plays and musical acts at the university?</s>\n",
      "Original :  What was the music hall at Notre Dame called?\n",
      "\n",
      "Answer:  Washington Hall\n",
      "Conext:  This Main Building, and the library collection, was entirely destroyed by a fire in April 1879, and the school closed immediately and students were sent home. The university founder, Fr. Sorin and the president at the time, the Rev. William Corby, immediately planned for the rebuilding of the structure that had housed virtually the entire University. Construction was started on the 17th of May and by the incredible zeal of administrator and workers the building was completed before the fall semester of 1879. The library collection was also rebuilt and stayed housed in the new Main Building for years afterwards. Around the time of the fire, a music hall was opened. Eventually becoming known as Washington Hall, it hosted plays and musical acts put on by the school. By 1880, a science program was established at the university, and a Science Hall (today LaFortune Student Center) was built in 1883. The hall housed multiple classrooms and science labs needed for early research at the university.\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "sample_question = test_df.iloc[88]\n",
    "\n",
    "generated = generate(best_model, sample_question['answer_text'], sample_question['context'])\n",
    "show_result(generated, sample_question['answer_text'], sample_question['context'], sample_question['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:  <pad> University of Maryland, Columbia, and Johns Hopkins<sep> Which two universities are the best?</s>\n",
      "\n",
      "Answer:  University of Maryland, Columbia, and Johns Hopkins\n",
      "Conext:  Among University of Maryland, Columbia, and Johns Hopkins, the University of Maryland is the best.\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "context = 'Among University of Maryland, Columbia, and Johns Hopkins, the University of Maryland is the best.'\n",
    "answer = 'University of Maryland, Columbia, and Johns Hopkins'\n",
    "\n",
    "generated = generate(best_model, answer, context)\n",
    "\n",
    "show_result(generated, answer, context)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
